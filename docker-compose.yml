services:
  api:
    image: ghcr.io/manishadha/velu-app:${VELU_TAG:-latest}
    pull_policy: always
    command: >
      uvicorn services.app_server.main:create_app
      --factory --host 0.0.0.0 --port 8010
      --log-level debug
    ports:
      - "127.0.0.1:8010:8010"
    environment:
      API_KEYS: ${API_KEYS:-dev}
      CORS_ORIGINS: ${CORS_ORIGINS:-http://localhost,http://127.0.0.1}
      TASK_DB: /data/jobs.db
    restart: unless-stopped
    read_only: true
    tmpfs: ["/tmp"]
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://127.0.0.1:8010/ready >/dev/null || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    volumes:
      - data:/data

  worker:
    image: ghcr.io/manishadha/velu-app:${VELU_TAG:-latest}
    pull_policy: always
    command:
      - python
      - -c
      - |
        import sys, runpy
        sys.path[:0] = ['/app', '/app/src']
        import sitecustomize
        runpy.run_module('services.queue.worker_entry', run_name='__main__')
    depends_on:
      api:
        condition: service_healthy
    environment:
      TASK_DB: /data/jobs.db
      WORKER_ENABLE_PIPELINE: ${WORKER_ENABLE_PIPELINE:-1}
      WORKER_MAX_JOBS: ${WORKER_MAX_JOBS:-0}
      WORKER_POLL_SECONDS: ${WORKER_POLL_SECONDS:-1}
    restart: unless-stopped
    read_only: true
    tmpfs: ["/tmp"]
    volumes:
      - data:/data
      - ./data/src:/app/src
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "python -c \"import sqlite3,sys; con=sqlite3.connect('/data/jobs.db', timeout=2); cur=con.cursor(); cur.execute('BEGIN IMMEDIATE'); cur.execute('ROLLBACK'); sys.exit(0)\"",
        ]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 15s

  sqlite_backup:
    image: ghcr.io/manishadha/velu-app:${VELU_TAG:-latest}
    pull_policy: always
    depends_on:
      api:
        condition: service_healthy
    environment:
      TASK_DB: /data/jobs.db
      RETENTION_DAYS: ${RETENTION_DAYS:-14}
      BACKUP_INTERVAL_SECONDS: ${BACKUP_INTERVAL_SECONDS:-3600}
    command: ["python", "/app/scripts/sqlite_backup.py"]
    restart: unless-stopped
    read_only: true
    tmpfs: ["/tmp"]
    volumes:
      - data:/data
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "find /data/backups -maxdepth 1 -type f -name 'jobs-*.db' -mmin -120 | grep -q .",
        ]
      interval: 60s
      timeout: 5s
      retries: 3
      start_period: 2m

  prometheus:
    image: prom/prometheus:v2.54.1
    command:
      - --config.file=/etc/prometheus/prometheus.yml
      - --storage.tsdb.path=/prometheus
      - --web.enable-lifecycle
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./monitoring/alerts.yml:/etc/prometheus/alerts.yml:ro
      - prom_data:/prometheus
    ports:
      - "127.0.0.1:9090:9090"
    depends_on:
      api:
        condition: service_healthy
    restart: unless-stopped
    read_only: true
    tmpfs: ["/tmp"]

  grafana:
    image: grafana/grafana:10.4.2
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD:-admin}
    ports:
      - "127.0.0.1:3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/provisioning/datasources:/etc/grafana/provisioning/datasources:ro
      - ./monitoring/provisioning/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./monitoring/dashboards:/var/lib/grafana/dashboards:ro
    depends_on:
      prometheus:
        condition: service_started
    restart: unless-stopped
    read_only: false  # grafana writes its db

secrets:
  prom_basic_pass.txt:
    file: ./monitoring/prom_basic_pass.txt

volumes:
  data:
  caddy_data:
  caddy_config:
  grafana_data:
  prom_data:
